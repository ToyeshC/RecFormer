data_path: 'recbole_data/'
dataset: small_dataset # FileNotFoundError: [Errno 2] No such file or directory: 'recbole_data/small_dataset/small_dataset.feat1CLS'
# dataset: pretrain_valid_ood # numpy.core._exceptions._ArrayMemoryError: Unable to allocate 20.9 GiB for an array with shape (11275053,) and data type <U498
# benchmark_filename: [train, valid, test]

load_col:
    inter: [user_id, item_id, timestamp]
    item: [item_id, title, categories, brand] 

PAD_TOKEN: "[PAD]" 
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
TIME_FIELD: timestamp

# Data loading settings
field_separator: "\t"
seq_separator: " "
max_item_list_length: 50
seq_len:
    item_id_list: 50

# Sequential dataset settings
MODEL_TYPE: Sequential
MODEL_INPUT_TYPE: Pointwise
LIST_SUFFIX: _list
ITEM_LIST_LENGTH_FIELD: item_length

# --- Training Settings ---
epochs: 0
train_batch_size: 1024
eval_batch_size: 512
learning_rate: 0.001
stopping_step: 10    # Early stopping based on valid_metric from OOD validation
loss_type: CE        
train_neg_sample_args: ~ 

metrics: [Recall, NDCG, MRR]
topk: [10]
valid_metric: NDCG@10 

eval_args:
    group_by: user # Group OOD validation data by user for evaluation
    order: TO      
    mode: full   